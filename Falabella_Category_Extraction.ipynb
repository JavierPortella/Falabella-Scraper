{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b48a3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from datetime import datetime, timedelta\n",
    "from logging import (\n",
    "    basicConfig,\n",
    "    ERROR,\n",
    "    FileHandler,\n",
    "    INFO,\n",
    "    log,\n",
    "    shutdown,\n",
    "    StreamHandler,\n",
    ")\n",
    "from os import environ, makedirs, path\n",
    "from time import localtime, strftime, time\n",
    "from traceback import TracebackException\n",
    "\n",
    "from openpyxl import load_workbook, Workbook\n",
    "from pandas import DataFrame\n",
    "from selenium.common.exceptions import TimeoutException, ElementNotInteractableException\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.service import Service\n",
    "from selenium.webdriver.remote.remote_connection import LOGGER as seleniumLogger\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from urllib3.connectionpool import log as urllibLogger\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d7d38525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tiempo:\n",
    "    \"\"\"\n",
    "    Representa el tiempo de ejecución del scraper\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    start_time : float\n",
    "        Hora de inicio de la ejecución del scraper en segundos\n",
    "    execution_date : str\n",
    "        Fecha de extracción de las categorias en formato %d/%m/%Y\n",
    "    start_hour : str\n",
    "        Hora de inicio de la ejecución del scraper en formato %H:%M:%S\n",
    "    end_hour : str\n",
    "        Hora de término de la ejecución del scraper en formato %H:%M:%S\n",
    "    quantity : int\n",
    "        Cantidad de categorías extraídas de la página de saga falabella\n",
    "    time_execution : str\n",
    "        Tiempo de ejecución del scraper en formato %d days, %H:%M:%S\n",
    "    category_per_min : float\n",
    "        Cantidad de categorías que puede extraer el scraper en un minuto\n",
    "    num_errors : int\n",
    "        Cantidad de errores ocurridos durante la ejecución del scraper\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    set_param_final():\n",
    "        Registra los parámetros finales cuando se termina de ejecutar el scraper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, current_date):\n",
    "        \"\"\"\n",
    "        Genera todos los atributos para una instancia de la clase Tiempo\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        current_date: datetime.date\n",
    "            Fecha en la que se ejecuta el scraper\n",
    "        \"\"\"\n",
    "        self._start_time = time()\n",
    "        self._execution_date = current_date.strftime(\"%d/%m/%Y\")\n",
    "        self._start_hour = strftime(\"%H:%M:%S\", localtime(self._start_time))\n",
    "        self._end_hour = None\n",
    "        self._quantity = 0\n",
    "        self._time_execution = None\n",
    "        self._category_per_min = None\n",
    "        self._num_errors = 0\n",
    "        log(INFO, f\"Hora de inicio: {self._start_hour}\")\n",
    "\n",
    "    @property\n",
    "    def execution_date(self):\n",
    "        \"\"\"Retorna el valor actual del atributo fecha\"\"\"\n",
    "        return self._execution_date\n",
    "\n",
    "    @property\n",
    "    def num_errors(self):\n",
    "        \"\"\"Retorna el valor actual o actualiza el valor del atributo num_error\"\"\"\n",
    "        return self._num_errors\n",
    "\n",
    "    @property\n",
    "    def quantity(self):\n",
    "        \"\"\"Retorna el valor actual o actualiza el valor del atributo cantidad\"\"\"\n",
    "        return self._quantity\n",
    "\n",
    "    @quantity.setter\n",
    "    def num_errors(self, num_errors):\n",
    "        self._num_errors = num_errors\n",
    "\n",
    "    @quantity.setter\n",
    "    def quantity(self, quantity):\n",
    "        self._quantity = quantity\n",
    "\n",
    "    def set_param_final(self):\n",
    "        \"\"\"\n",
    "        Registra los parámetros finales para medir el tiempo de ejecución del scraper\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        end = time()\n",
    "        self._num_errors += 1\n",
    "        self._end_hour = strftime(\"%H:%M:%S\", localtime(end))\n",
    "        total = end - self._start_time\n",
    "        self._time_execution = str(timedelta(seconds=total)).split(\".\")[0]\n",
    "        self._category_per_min = round(self._quantity / (total / 60), 2)\n",
    "        log(INFO, f\"Se halló {self._num_errors} errores\")\n",
    "        log(INFO, f\"Categorías Extraídas: {self._quantity}\")\n",
    "        log(INFO, f\"Hora Fin: {self._end_hour}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e6b2a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Errores:\n",
    "    \"\"\"\n",
    "    Representa a los errores ocurridos durante la ejecución de un scraper\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    errors : dict\n",
    "        Conjunto de datos que contiene toda información de los errores ocurridos durante la ejecución del scraper\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    add_new_error(error, enlace):\n",
    "        Agrega la información de un nuevo error al conjunto de datos errores\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Genera todos los atributos para una instancia de la clase Errores\n",
    "        \"\"\"\n",
    "        self._errors = {\n",
    "            \"Clase\": [],\n",
    "            \"Mensaje\": [],\n",
    "            \"Linea de Error\": [],\n",
    "            \"Codigo Error\": [],\n",
    "            \"Origen\": [],\n",
    "            \"Publicacion\": [],\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def errors(self):\n",
    "        \"\"\"Retorna el valor actual del atributo errors\"\"\"\n",
    "        return self._errors\n",
    "\n",
    "    def add_new_error(self, error, description, link):\n",
    "        \"\"\"\n",
    "        Agrega la información de un nuevo error al conjunto de datos errors\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        error: Exception\n",
    "            Error ocurrido durante la ejecución del scraper\n",
    "        link: str\n",
    "            Enlace de una categoría de la página de saga falabella\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        log(ERROR, f\"Error:\\n{error}\")\n",
    "        traceback_error = TracebackException.from_exception(error)\n",
    "        error_stack = traceback_error.stack[0]\n",
    "        self._errors[\"Clase\"].append(traceback_error.exc_type)\n",
    "        self._errors[\"Mensaje\"].append(traceback_error._str)\n",
    "        self._errors[\"Linea de Error\"].append(error_stack.lineno)\n",
    "        self._errors[\"Codigo Error\"].append(error_stack.line)\n",
    "        self._errors[\"Origen\"].append(description)\n",
    "        self._errors[\"Publicacion\"].append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "24a8f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Representa al conjunto de datos generado por el scraper\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    dataset : pandas.core.frame.DataFrame\n",
    "        Dataframe que contiene toda información de las categorías de la página de saga falabella\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    filter_duplicate_values(column_filters):\n",
    "        Elimina todos los registros con valores duplicados excepto la primera aparición del mismo\n",
    "    get_column_values(column_name):\n",
    "        Retorna una lista de valores de una columna existente en el dataset\n",
    "    length():\n",
    "        Retorna la cantidad de registros existentes en el dataset\n",
    "    merge_dataset(dataset_to_merge, left_on, right_on, how):\n",
    "        Combina la información proveniente de un dataset con el del dataset actual bajo ciertos criterios de combinación\n",
    "    rename_columns(dict_columns):\n",
    "        Renombra una o varias columnas del dataset\n",
    "    save_dataset(filename, encoding):\n",
    "        Guarda toda la información del dataset en un archivo .csv\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Genera todos los atributos para una instancia de la clase Dataset\n",
    "        \"\"\"\n",
    "        self._dataset = DataFrame(data)\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"Retorna el valor actual del diccionario de datos dataset\"\"\"\n",
    "        return self._dataset\n",
    "\n",
    "    def filter_duplicate_values(self, column_filters):\n",
    "        \"\"\"\n",
    "        Elimina todos los registros con valores duplicados excepto la primera aparición del mismo\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        column_filters: list\n",
    "            Columna o columnas para identificar valores duplicados\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self._dataset.drop_duplicates(\n",
    "            column_filters, keep=\"first\", inplace=True, ignore_index=True\n",
    "        )\n",
    "\n",
    "    def get_column_values(self, column_name):\n",
    "        \"\"\"\n",
    "        Retorna una lista de valores de una columna existente en el dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        column_name: str\n",
    "            Nombre de la columna\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "        \"\"\"\n",
    "        return self._dataset[column_name].values.tolist()\n",
    "\n",
    "    def length(self):\n",
    "        \"\"\"\n",
    "        Retorna la cantidad de registros existentes en el dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "        \"\"\"\n",
    "        return len(self._dataset)\n",
    "\n",
    "    def merge_dataset(self, dataset_to_merge, left_on, right_on, how):\n",
    "        \"\"\"\n",
    "        Combina la información proveniente de un dataset con el del dataset actual bajo ciertos criterios de combinación\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset_to_merge: pandas.core.frame.DataFrame\n",
    "            Dataset con el que se va a combinar\n",
    "        left_on: label or list\n",
    "            Nombre de la(s) columna(s) del dataset actual usadas como criterio de combinación\n",
    "        right_on: str\n",
    "            Nombre de la(s) columna(s) del dataset pasado como parámetro usadas como criterio de combinación\n",
    "        how: str\n",
    "            Tipo de combinación a realizarse\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self._dataset = self._dataset.merge(\n",
    "            dataset_to_merge, how=how, left_on=left_on, right_on=right_on\n",
    "        )\n",
    "\n",
    "    def rename_columns(self, dict_columns):\n",
    "        \"\"\"\n",
    "        Renombra una o varias columnas del dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dict_columns: dict\n",
    "            Diccionario que contenga como 'key' el nombre actual de la columna y 'value' el nombre a reemplazar\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self._dataset.rename(dict_columns, axis=1, inplace=True)\n",
    "\n",
    "    def save_dataset(self, filename, encoding):\n",
    "        \"\"\"\n",
    "        Guarda toda la información del dataset en un archivo .csv\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str\n",
    "            Nombre del archivo\n",
    "        encoding: str\n",
    "            Codificación usada para guardar el archivo\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self._dataset.to_csv(filename, index=False, encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3faf67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScraperFalabellaCategory:\n",
    "    \"\"\"\n",
    "    Representa a un bot para hacer web scraping en saga falabella\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    time : Tiempo\n",
    "        Objeto de la clase Tiempo que maneja información del tiempo de ejecución del scraper\n",
    "    errors : Errores\n",
    "        Objeto de la clase Errores que maneja información de los errores ocurridos durante la ejecución del scraper\n",
    "    df_category : Dataset\n",
    "        Objeto de la clase Dataset que maneja información de las categorías extraídas por el scraper\n",
    "    driver: webdriver.Chrome\n",
    "        Objeto de la clase webdriver que maneja un navegador para hacer web scraping\n",
    "    wait : WebDriverWait\n",
    "        Objeto de la clase WebDriverWait que maneja el Tiempo de espera durante la ejecución del scraper\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    enter_website(url):\n",
    "        Entra a una página web dado una url\n",
    "    maximize_window():\n",
    "        Pone a pantalla completa el navegador\n",
    "    get_element(selector, xpath):\n",
    "        Localiza y retorna un elemento en la página web dado un criterio de búsqueda\n",
    "    get_elements(selector, path):\n",
    "        Localiza y retorna una lista de todos los elementos en la página web que coincidan con un criterio de búsqueda\n",
    "    close_popups():\n",
    "        Cierra todas las ventanas emergentes\n",
    "    get_category_info():\n",
    "        Retorna un conjunto de datos que contiene toda la información de las categorías de saga falabella\n",
    "    get_subcategory_info(category_links):\n",
    "        Retorna un conjunto de datos que contiene toda la información de las subcategorías de saga falabella\n",
    "    extract_categories(level):\n",
    "        Extrae la información de las categorías de saga falabella hasta cierto nivel de profundidad\n",
    "    guardar_datos(filetype, folder, filename):\n",
    "        Guarda los datos o errores obtenidos durante la ejecución del scraper\n",
    "    guardar_tiempos(filename, sheet_name):\n",
    "        Guarda la información del tiempo de ejecución del scraper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, current_date):\n",
    "        \"\"\"\n",
    "        Genera todos los atributos para una instancia de la clase ScraperFb\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        current_date: datetime.date\n",
    "            Fecha en la que se ejecuta el scraper\n",
    "        \"\"\"\n",
    "        log(INFO, \"Inicializando scraper\")\n",
    "        self._time = Tiempo(current_date)\n",
    "        self._errors = Errores()\n",
    "        self._df_category = None\n",
    "        options = ChromeOptions()\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        prefs = {\"profile.default_content_setting_values.notifications\": 2}\n",
    "        options.add_experimental_option(\"prefs\", prefs)\n",
    "        self._driver = Chrome(service=service, options=options)\n",
    "        self._wait = WebDriverWait(self._driver, 8)\n",
    "\n",
    "    def enter_website(self, url):\n",
    "        \"\"\"\n",
    "        Entra a una página web dado una url\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        url: str\n",
    "            Link de una página web\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        log(INFO, f\"Accediendo a {url}\")\n",
    "        self._driver.get(url)\n",
    "\n",
    "    def maximize_window(self):\n",
    "        \"\"\"\n",
    "        Pone a pantalla completa el navegador\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self._driver.maximize_window()\n",
    "\n",
    "    def get_element(self, selector, path):\n",
    "        \"\"\"\n",
    "        Localiza y retorna un elemento en la página web dado un criterio de búsqueda\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selector: str\n",
    "            Selector a ser usado para localizar un elemento en la página web\n",
    "        xpath: str\n",
    "            Ruta de un elemento web a ser usado por el selector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        selenium.webdriver.remote.webelement.WebElement\n",
    "        \"\"\"\n",
    "        return self._wait.until(lambda x: x.find_element(selector, path))\n",
    "\n",
    "    def get_elements(self, selector, path):\n",
    "        \"\"\"\n",
    "        Localiza y retorna una lista de todos los elementos en la página web que coincidan con un criterio de búsqueda\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selector: str\n",
    "            Selector a ser usado para localizar varios elementos en la página web\n",
    "        xpath: str\n",
    "            Ruta de los elementos web a ser usado por el selector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "        \"\"\"\n",
    "        return self._wait.until(lambda x: x.find_elements(selector, path))\n",
    "\n",
    "    def close_popups(self):\n",
    "        \"\"\"\n",
    "        Cierra todas las ventanas emergentes\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        log(INFO, \"Cerrando ventanas emergentes\")\n",
    "        self.get_element(By.ID, \"testId-accept-cookies-btn\").click()\n",
    "        # self.get_element(By.CLASS_NAME, \"dy-lb-close\").click()\n",
    "\n",
    "    def get_category_info(self):\n",
    "        \"\"\"\n",
    "        Retorna un conjunto de datos que contiene toda la información de las categorías de saga falabella\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dataset\n",
    "        \"\"\"\n",
    "        log(INFO, \"Obteniendo información de las categorías principales\")\n",
    "        # Accediendo al menú principal de saga falabella\n",
    "        self.get_element(By.CLASS_NAME, \"TopMenu-module_categoryWrapper__Q_tEE\").click()\n",
    "\n",
    "        # Registrando la lista de categorías que nos muestra el menú princial de saga falabella\n",
    "        category_list = self.get_elements(\n",
    "            By.XPATH, \"//a[@class='SideMenu-module_itemWrapper__3IXOl']\"\n",
    "        )\n",
    "        # Lista que contiene los links de las subcategorías de saga falabella\n",
    "        subcategory_links = []\n",
    "\n",
    "        # Diccionario de datos que almacena la información de las categorías de saga falabella\n",
    "        category_info = {}\n",
    "\n",
    "        log(INFO, f\"Navegando por el menú principal de saga falabella\")\n",
    "        for category in category_list:\n",
    "            try:\n",
    "                # Dando click a una categoría mostrada por el menú principal\n",
    "                category.click()\n",
    "\n",
    "                # Extrayendo los links de las subcategorías de la categoría actualmente seleccionada\n",
    "                subcategory_list = self.get_elements(\n",
    "                    By.XPATH,\n",
    "                    \"//a[@class='SubCategories-module_hover-effect__1E3TD SubCategories-module_list-title__3bskI']\",\n",
    "                )\n",
    "\n",
    "                # Recorriendo la lista de subcategorías de la categoría actualmente seleccionada\n",
    "                for subcategory in subcategory_list:\n",
    "                    # Recuperando el link de la subcategoría\n",
    "                    url_subcat = subcategory.get_attribute(\"href\")\n",
    "\n",
    "                    # Comprobando que el link de la subcategoría contenga category\n",
    "                    if url_subcat.find(\"category\") == -1:\n",
    "                        continue\n",
    "\n",
    "                    # Guardando el link de la subcategoría en una lista\n",
    "                    subcategory_links.append(url_subcat)\n",
    "\n",
    "            except TimeoutException as error:\n",
    "                self._errors.add_new_error(error, \"Menú de categorías\", None)\n",
    "\n",
    "        # Cerrando ventana emergente molesta\n",
    "        self.enter_website(subcategory_links[0])\n",
    "        self.get_element(By.ID, \"testId-modal-close\").click()\n",
    "\n",
    "        # Recopilando los links de las categorías principales\n",
    "        for link in subcategory_links:\n",
    "            # Entrando al link de una subcategoría\n",
    "            self.enter_website(link)\n",
    "            # Flag que indica si se ha llegado a la categoría principal\n",
    "            no_error = True\n",
    "\n",
    "            # Mientras no sea la categoría principal\n",
    "            while no_error:\n",
    "                try:\n",
    "                    # Navegar a la categoría padre de la subcategoría\n",
    "                    self.get_element(\n",
    "                        By.XPATH, \"//a[@class='jsx-2883309125 l1category']\"\n",
    "                    ).click()\n",
    "\n",
    "                except ElementNotInteractableException as error:\n",
    "                    self._errors.add_new_error(\n",
    "                        error, \"Extracción categoría principal\", link\n",
    "                    )\n",
    "                    no_error = False\n",
    "\n",
    "            # Obteniendo el nombre de la categoría principal\n",
    "            name = self.get_element(\n",
    "                By.XPATH, \"//h1[@class='jsx-2883309125 l2category']\"\n",
    "            ).text\n",
    "            log(INFO, f\"Categoría Obtenida: {name}\")\n",
    "            # Guardando el nombre y link de la categoría principal\n",
    "            category_info[name] = self._driver.execute_script(\"return document.URL\")\n",
    "\n",
    "        log(INFO, \"Categorías principales recuperadas satisfactoriamente\")\n",
    "        return Dataset({\"Name\": category_info.keys(), \"Link_0\": category_info.values()})\n",
    "\n",
    "    def get_subcategory_info(self, category_links):\n",
    "        \"\"\"\n",
    "        Retorna un conjunto de datos que contiene toda la información de las subcategorías de saga falabella\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        category_links: list\n",
    "            Lista de links de las categorías de saga falabella\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dataset\n",
    "        \"\"\"\n",
    "        subcategory_info = {\n",
    "            \"Link\": [],\n",
    "            \"Subcategory\": [],\n",
    "            \"Link_1\": [],\n",
    "        }\n",
    "        for category_level in category_links:\n",
    "            try:\n",
    "                self.enter_website(category_level)\n",
    "                data = self.get_element(By.XPATH, \"//script[@id='__NEXT_DATA__']\")\n",
    "                data_json = loads(data.get_attribute(\"text\"))\n",
    "                filters_value = data_json[\"props\"][\"pageProps\"][\"facets\"][:3]\n",
    "                for filter_value in filters_value:\n",
    "                    if filter_value[\"name\"] == \"Categoría\":\n",
    "                        data_values = filter_value[\"values\"]\n",
    "                        for item in data_values:\n",
    "                            title = item[\"title\"]\n",
    "                            subcategory_info[\"Link_1\"].append(\n",
    "                                \"https://tienda.falabella.com.pe/falabella-pe/category/\"\n",
    "                                + item[\"id\"]\n",
    "                                + \"/\"\n",
    "                                + title.replace(\" \", \"-\")\n",
    "                            )\n",
    "                            subcategory_info[\"Link\"].append(category_level)\n",
    "                            subcategory_info[\"Subcategory\"].append(title)\n",
    "                        break\n",
    "\n",
    "            except (IndexError, KeyError, TimeoutException) as error:\n",
    "                self._errors.add_new_error(\n",
    "                    error, \"Extracción categorías secundarias\", category_level\n",
    "                )\n",
    "\n",
    "        return Dataset(subcategory_info)\n",
    "\n",
    "    def extract_categories(self, level):\n",
    "        \"\"\"\n",
    "        Extrae la información de las categorías de saga falabella hasta cierto nivel de profundidad\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level: int\n",
    "            Cantidad de niveles de jerarquía para la clasificación de las categorías de saga falabella\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if level <= 0:\n",
    "            return\n",
    "\n",
    "        self._df_category = self.get_category_info()\n",
    "\n",
    "        if level == 1:\n",
    "            return\n",
    "\n",
    "        level -= 1\n",
    "        for i in range(level):\n",
    "            df_subcategory = self.get_subcategory_info(\n",
    "                self._df_category.get_column_values(\"Link_0\")\n",
    "            )\n",
    "            if df_subcategory.length() == 0:\n",
    "                return\n",
    "            join_col = \"Link_\" + str(i)\n",
    "            df_subcategory.rename_columns(\n",
    "                {\n",
    "                    \"Link\": join_col,\n",
    "                    \"Subcategory\": \"Subcategory_\" + str(i + 1),\n",
    "                    \"Link_1\": \"Link_\" + str(i + 1),\n",
    "                }\n",
    "            )\n",
    "            self._df_category.merge_dataset(\n",
    "                df_subcategory.dataset, join_col, join_col, \"left\"\n",
    "            )\n",
    "\n",
    "    def save_data(\n",
    "        self,\n",
    "        filetype,\n",
    "        folder,\n",
    "        filename,\n",
    "        encoding,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Guarda los datos o errores obtenidos durante la ejecución del scraper\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filetype: {'Data', 'Error'} str:\n",
    "            Indica si la información son datos de las categorías o de los errores.\n",
    "        folder: str\n",
    "            Ruta del archivo\n",
    "        filename: str\n",
    "            Nombre del archivo\n",
    "        encoding: str\n",
    "            Codificación usada para guardar el archivo\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        log(INFO, f\"Guardando {filetype}\")\n",
    "        # Comprobando si el valor ingresado para la variable filetype es correcto\n",
    "        if filetype == \"Data\":\n",
    "            # Registrando toda la información de las categorías extraídas por el scraper\n",
    "            dataset = self._df_category\n",
    "            # Registrando la cantidad de categorías extraídas por el scraper\n",
    "            self._time.quantity = dataset.length()\n",
    "        elif filetype == \"Error\":\n",
    "            # Registrando toda la información de los errores ocurridos durante la ejecución del scraper\n",
    "            dataset = Dataset(self._errors.errors)\n",
    "            # Registrando la cantidad de errores ocurridos durante la ejecución del scraper\n",
    "            self._time.num_errors = dataset.length()\n",
    "        else:\n",
    "            log(\n",
    "                INFO,\n",
    "                f\"El archivo de tipo {filetype} no está admitido. Solo se aceptan los valores Data y Error\",\n",
    "            )\n",
    "            log(\n",
    "                ERROR,\n",
    "                f\"El archivo de tipo {filetype} no se va a guardar por no ser de tipo Data o Error\",\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # Registrando la cantidad de información que contiene el dataset\n",
    "        quantity = dataset.length()\n",
    "\n",
    "        # Comprobando que el dataset contenga información\n",
    "        if quantity == 0:\n",
    "            log(\n",
    "                INFO,\n",
    "                f\"El archivo de tipo {filetype} no se va a guardar por no tener información\",\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # Generando la ruta donde se va a guardar la información\n",
    "        datetime_obj = datetime.strptime(self._time.execution_date, \"%d/%m/%Y\")\n",
    "        filepath = path.join(folder, datetime_obj.strftime(\"%d-%m-%Y\"))\n",
    "        # Generando el nombre del archivo que va a contener la información\n",
    "        filename = (\n",
    "            filename\n",
    "            + \"_\"\n",
    "            + datetime_obj.strftime(\"%d%m%Y\")\n",
    "            + \"_\"\n",
    "            + str(quantity)\n",
    "            + \".csv\"\n",
    "        )\n",
    "\n",
    "        # Verificando si la ruta donde se va a guardar la información existe\n",
    "        if not path.exists(filepath):\n",
    "            # Creando la ruta donde se va a guardar la información\n",
    "            makedirs(filepath)\n",
    "\n",
    "        # Guardando la información en un archivo de tipo excel\n",
    "        dataset.save_dataset(path.join(filepath, filename), encoding)\n",
    "        log(INFO, f\"{filetype} Guardados Correctamente\")\n",
    "\n",
    "    def save_time_execution(self, filename, sheet_name):\n",
    "        \"\"\"\n",
    "        Guarda la información del tiempo de ejecución del scraper\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str\n",
    "            Nombre del archivo\n",
    "        sheet_name: str\n",
    "            Nombre de la hoja de cálculo\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Guardando los parametros finales del tiempo de ejecución del scraper\n",
    "        self._time.set_param_final()\n",
    "        log(INFO, \"Guardando tiempos\")\n",
    "        # Variable que indica si el encabezados existe o no en el archivo de excel\n",
    "        header_exist = True\n",
    "\n",
    "        # Verificando si el archivo existe o no\n",
    "        if path.isfile(filename):\n",
    "            # Leendo el archivo\n",
    "            wb_time = load_workbook(filename)\n",
    "        else:\n",
    "            # Creando un archivo de tipo workbook\n",
    "            wb_time = Workbook()\n",
    "            wb_time.worksheets[0].title = sheet_name\n",
    "\n",
    "        # Comprobando si ya existe un sheet con el nombre indicado en la variable sheet_name\n",
    "        if sheet_name not in [ws.title for ws in wb_time.worksheets]:\n",
    "            # Creando un nuevo sheet\n",
    "            wb_time.create_sheet(sheet_name)\n",
    "            # Especificar que no existen encabezados en el nuevo sheet\n",
    "            header_exist = False\n",
    "        # Seleccionar el sheet deseado donde se va a guardar la información\n",
    "        worksheet = wb_time[sheet_name]\n",
    "\n",
    "        # Comprobando si el encabezados existen o no\n",
    "        if not header_exist:\n",
    "            # Lista que contiene los encabezados a ser insertados\n",
    "            keys = [\n",
    "                \"Fecha\",\n",
    "                \"Hora Inicio\",\n",
    "                \"Hora Fin\",\n",
    "                \"Cantidad\",\n",
    "                \"Tiempo Ejecucion (min)\",\n",
    "                \"Categorias / Minuto\",\n",
    "                \"Errores\",\n",
    "            ]\n",
    "            # Insertando los encabezados al worksheet\n",
    "            worksheet.append(keys)\n",
    "\n",
    "        # Lista que contiene los valores a ser insertados\n",
    "        values = list(self._time.__dict__.values())[1:]\n",
    "        # Insertando la información del tiempo al worksheet\n",
    "        worksheet.append(values)\n",
    "        # Guardar la información en un archivo excel\n",
    "        wb_time.save(filename)\n",
    "        # Cerrar el archivo excel\n",
    "        wb_time.close()\n",
    "        log(INFO, \"Tiempos Guardados Correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cc470eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_log(\n",
    "    log_folder, log_filename, log_file_mode, log_file_encoding, current_date\n",
    "):\n",
    "    \"\"\"\n",
    "    Función que configura los logs para rastrear al programa\n",
    "        Parameter:\n",
    "                log_folder (str): Carpeta donde se va a generar el archivo log\n",
    "                log_filename (str): Nombre del archivo log a ser generado\n",
    "                log_file_mode (str): Modo de guardado del archivo\n",
    "                log_file_encoding (str): Codificación usada para el archivo\n",
    "                current_date (datetime): Fecha actual de la creación del archivo log\n",
    "        Returns:\n",
    "                None\n",
    "    \"\"\"\n",
    "    # Mostrar solo los errores de los registros que maneja selenium\n",
    "    seleniumLogger.setLevel(ERROR)\n",
    "    environ[\"WDM_LOG\"] = \"0\"\n",
    "    # Mostrar solo los errores de los registros que maneja urllib\n",
    "    urllibLogger.setLevel(ERROR)\n",
    "    # Generando la ruta donde se va a guardar los registros de ejecución\n",
    "    log_path = path.join(log_folder, current_date.strftime(\"%d-%m-%Y\"))\n",
    "    # Generando el nombre del archivo que va a contener los registros de ejecución\n",
    "    log_filename = log_filename + \"_\" + current_date.strftime(\"%d%m%Y\") + \".log\"\n",
    "    # Verificando si la ruta donde se va a guardar los registros de ejecución existe\n",
    "    if not path.exists(log_path):\n",
    "        # Creando la ruta donde se va a guardar los registros de ejecución\n",
    "        makedirs(log_path)\n",
    "\n",
    "    # Configuración básica de los logs que maneja este programa\n",
    "    basicConfig(\n",
    "        format=\"%(asctime)s %(message)s\",\n",
    "        level=INFO,\n",
    "        handlers=[\n",
    "            StreamHandler(),\n",
    "            FileHandler(\n",
    "                path.join(log_path, log_filename), log_file_mode, log_file_encoding\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def validate_params(parameters):\n",
    "    \"\"\"\n",
    "    Función que valida si los parámetros a usar están definidos\n",
    "         Parameter:\n",
    "                 parametros (list): Lista de parámetros\n",
    "\n",
    "        Returns:\n",
    "               None\n",
    "    \"\"\"\n",
    "    for param in parameters:\n",
    "        log(INFO, f\"{param=}\")\n",
    "        # Verifica que el parámetro haya sido definido\n",
    "        if not param or param == \"\":\n",
    "            # Retorna false si algunos de los parámetros no fue definido\n",
    "            return False\n",
    "\n",
    "    # Retorna verdadero si todos los parámetros fueron definidos\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1ff2c6d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Formato para el debugger\n",
    "        current_date = datetime.now().date()\n",
    "        config_log(\"Log\", \"fb_ropa_log\", \"w\", \"utf-8\", current_date)\n",
    "        log(INFO, \"Configurando Formato Básico del Debugger\")\n",
    "\n",
    "        # Url de la tienda de saga falabella\n",
    "        URL = \"https://tienda.falabella.com.pe/falabella-pe\"\n",
    "\n",
    "        # Codificación usada para guardar los archivos\n",
    "        FILE_ENCODING = \"utf-8-sig\"\n",
    "\n",
    "        # Parámetros para guardar la data extraída por el scraper\n",
    "        DATA_FILENAME = \"falabella_category\"\n",
    "        DATA_FOLDER = \"Data\"\n",
    "\n",
    "        # Parámetros para guardar los errores durante la ejecución por el scraper\n",
    "        ERROR_FILENAME = \"falabella_error\"\n",
    "        ERROR_FOLDER = \"Error\"\n",
    "\n",
    "        # Parámetros para guardar la medición de la ejecución del scraper\n",
    "        TIME_FILENAME = \"Tiempos.xlsx\"\n",
    "        TIME_SHEET_NAME = \"Categorias\"\n",
    "\n",
    "        log(INFO, \"Validando parámetros a usar\")\n",
    "        if validate_params(\n",
    "            [\n",
    "                FILE_ENCODING,\n",
    "                DATA_FILENAME,\n",
    "                DATA_FOLDER,\n",
    "                ERROR_FILENAME,\n",
    "                ERROR_FOLDER,\n",
    "                TIME_FILENAME,\n",
    "                TIME_SHEET_NAME,\n",
    "            ]\n",
    "        ):\n",
    "            log(ERROR, \"Parámetros incorrectos\")\n",
    "            return\n",
    "        log(INFO, \"Parámetros válidos\")\n",
    "\n",
    "        scraper = ScraperFalabellaCategory(current_date)\n",
    "        #\n",
    "        scraper.enter_website(URL)\n",
    "        scraper.maximize_window()\n",
    "\n",
    "        # Cerrar ventanas emergentes molestas\n",
    "        scraper.close_popups()\n",
    "\n",
    "        # Extraer las categorías\n",
    "        scraper.extract_categories(2)\n",
    "\n",
    "        # Guardando la data extraída por el scraper\n",
    "        scraper.save_data(\"Data\", DATA_FOLDER, DATA_FILENAME, FILE_ENCODING)\n",
    "\n",
    "        # Guardando los errores extraídos por el scraper\n",
    "        scraper.save_data(\"Error\", ERROR_FOLDER, ERROR_FILENAME, FILE_ENCODING)\n",
    "\n",
    "        # Guardando los tiempos durante la ejecución del scraper\n",
    "        scraper.save_time_execution(TIME_FILENAME, TIME_SHEET_NAME)\n",
    "        log(INFO, \"Programa finalizado\")\n",
    "\n",
    "    except Exception as error:\n",
    "        log(ERROR, f\"Error: {error}\")\n",
    "        log(INFO, \"Programa ejecutado con fallos\")\n",
    "    finally:\n",
    "        # Liberar el archivo log\n",
    "        shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03518b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5297a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"categories.csv\")\n",
    "df_1 = pd.read_csv(\"subcategory_1.csv\")\n",
    "df_2 = pd.read_csv(\"subcategory_2.csv\")\n",
    "df_3 = pd.read_csv(\"subcategory_3.csv\")\n",
    "df_4 = pd.read_csv(\"subcategory_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a8b298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efe637be",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_links = df[\"Link\"].values.tolist() + df_1[\"Link_1\"].values.tolist() + df_2[\"Link_2\"].values.tolist() + df_3[\"Link_3\"].values.tolist() + df_4[\"Link_4\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fe514e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixed = pd.read_csv(\"Falabella_category.csv\")\n",
    "df_old = df_fixed.stack().groupby(level=0).apply(list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "dcac8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_links = [x[-1] for x in df_old]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81c656d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "old_size = len(whole_links)\n",
    "whole_links = list(set(whole_links))\n",
    "new_size = len(whole_links)\n",
    "print(old_size - new_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bccb518b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tienda.falabella.com.pe/falabella-pe/category/cat2600464/Salud\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG11979/Equipos-médicos-y-ortopédicos\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14356/Mascarillas\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG33811/Juego-de-dormitorio-1.5-Plazas\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/cat12990589/Balanzas\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14353/Equipos-ortopédicos\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14373/Rehabilitación-calor-y-frío\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14388/Vitaminas\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/cat40501/Monitores-de-salud\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG33643/Otros-Monitores-de-salud\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/cat7230475/Vitaminas-y-suplementos\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14375/Glucómetros\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14376/Oxímetros\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG33642/Insumos-medicos\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14351/Vibradores-y-Dildos\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG11978/Bienestar-sexual\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG33641/Equipamiento-medico\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG11981/Medicina-alternativa\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14344/Juguetes-Sexuales\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14352/Equipos-de-movilidad\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14338/Anticonceptivos-para-Hombre\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14357/Homeopatía\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG33814/Juego-de-dormitorio-Queen\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14342/Estimuladores-Sexuales\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14332/Artículos-para-el-cuidado-de-la-nariz\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14387/Suplementos\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14339/Anticonceptivos-para-Mujer\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14336/Aceites-corporales\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG33812/Juego-de-dormitorio-2-Plazas\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG33813/Juego-de-dormitorio-King\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14322/Termómetros\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14334/Artículos-para-el-cuidado-de-los-ojos-y-lentes\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG11980/Medicamentos\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14333/Artículos-para-el-cuidado-de-las-orejas\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14331/Artículos-para-dejar-de-fumar\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14349/Potencializadores\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG11976/Accesorios-de-salud\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14347/Lubricantes-y-humectantes\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/cat12940567/Medicina-deportiva\n",
      "https://tienda.falabella.com.pe/falabella-pe/category/CATG14365/Aromaterapia-y-spa\n"
     ]
    }
   ],
   "source": [
    "visited = set()\n",
    "dup = {x for x in whole_links if x in visited or (visited.add(x) or False)}\n",
    "for link in dup:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a55cc3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Dormitorio Juego de dormitorio\n",
      "Especiales Especial Hogar\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Dormitorio Juego de dormitorio\n",
      "Especiales Especial Hogar\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Dormitorio Juego de dormitorio\n",
      "Especiales Especial Hogar\n",
      "----------------------------------------------------------------------\n",
      "Dormitorio Juego de dormitorio\n",
      "Especiales Especial Hogar\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Belleza, higiene y salud Salud\n",
      "Especiales Especial Tecnología\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dups in list(dup):\n",
    "    for item in df_old:\n",
    "        if item[-1] == dups:\n",
    "            print(item[0], item[2])\n",
    "    print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7783c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "agua = pd.DataFrame({\"a\":[1,2,3,4,5,8,36,45]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b6b460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
    "                    'value': [1, 2, 3, 5]})\n",
    "df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
    "                    'value': [5, 6, 7, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732f71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.merge(df2, left_on='lkey', right_on='rkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "791a2ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tecnología',\n",
       " 'Electrohogar',\n",
       " 'Moda y accesorios',\n",
       " 'Muebles y Organización',\n",
       " 'Decohogar',\n",
       " 'Dormitorio',\n",
       " 'Juguetería',\n",
       " 'Niños y Juguetería',\n",
       " 'Mundo Bebé',\n",
       " 'Belleza, higiene y salud',\n",
       " 'Especiales',\n",
       " 'Deportes y aire libre']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Name\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75afc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
